{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we explore the phenomenon of adversarial examples, and *adversarial training*, which is a way to improve the robustness of our models with respect to targetted perturbations of the input.\n",
    "\n",
    "Also pay attention to the following usage:\n",
    "  * `tf.GradientTape()` for taking gradients. Note that this requires eager execution (`Tensorflow` version >= 2.0)\n",
    "  * The `Adversarial Robustness Toolbox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "sns.set(font_scale=1.5, style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load our trained model previously for the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('cifar10_baseline_augment.h5')\n",
    "model.add(tf.keras.layers.Activation('softmax'))  # Add softmax here for easier logits visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Here are the names of the classes\n",
    "text_labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Predicted Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a handy function to plot a given image, as well as our model's predictions (probabilities) of its classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_probs(image, model):\n",
    "    logits = model.predict(image).squeeze()\n",
    "\n",
    "    with sns.axes_style('dark'):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10 ,4))\n",
    "        ax[0].imshow(image[0])\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].barh(text_labels, logits)\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this on a random image. Observe that the prediction is quite precise, in that our model is predicting the correct label with a probability very close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 123\n",
    "image = x_test[image_id][None, :, :, :]\n",
    "label = y_test[image_id][None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Label = {text_labels[label.argmax(1)[0]]}')\n",
    "plot_image_and_probs(image, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding an Adversarial Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us find an adverarial example by the means of the gradient descent (or rather, ascent) method. This is known as the fast gradient (sign) method (FGSM)\n",
    "$$\n",
    "    \\mathbf{z}_{j+1} = \\mathbf{z}_{j}\n",
    "    + \n",
    "    \\epsilon \n",
    "    \\text{Sign}\n",
    "    \\left(\n",
    "        \\nabla_\\mathbf{z}\n",
    "        L(\\hat{y}(\\mathbf{z}_j;\\theta), y) \n",
    "    \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.losses.categorical_crossentropy\n",
    "perturbed_image = tf.constant(\n",
    "    image + 0.05*np.random.normal(size=image.shape), dtype='float32')\n",
    "epsilon = 0.01\n",
    "\n",
    "for _ in tqdm.tqdm(range(1)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(perturbed_image)\n",
    "        prediction = model(perturbed_image)\n",
    "        loss = loss_func(label, prediction)\n",
    "        gradient = tape.gradient(loss, perturbed_image)\n",
    "        signed_grad = tf.sign(gradient)\n",
    "        perturbed_image = perturbed_image + epsilon * signed_grad\n",
    "        perturbed_image = tf.clip_by_value(perturbed_image, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_image_numpy = perturbed_image.numpy()\n",
    "plot_image_and_probs(perturbed_image_numpy, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a very small perturbation can induce a large deviation in the prediction! In other words, are models are very *brittle*. How can we make it more robust?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark.** Note that a better way to implement such attacks would be to use some adversarial attack/defense framework, e.g. one introduced below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to improve adversarial robustness is by adversarial training. The basic idea is to introduce adversarial perturbations to the training dataset during model fitting. There are many methods to do this.\n",
    "\n",
    "Here, we will use the [Adversarial Robustness 360 Toolbox](https://adversarial-robustness-toolbox.readthedocs.io/en/latest/index.html), which is compatible with `Keras`. \n",
    "\n",
    "As an alternative, you can also use the [Neural Structured Learning](https://www.tensorflow.org/neural_structured_learning/) API provided by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()  # Disable eager execution, as currently required by ART\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.defences.trainer import AdversarialTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adv = load_model('cifar10_baseline_augment.h5')\n",
    "model_adv.add(tf.keras.layers.Activation('softmax'))\n",
    "model_adv.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = KerasClassifier(model_adv, clip_values=(0, 1), use_logits=False)\n",
    "fgm = FastGradientMethod(model_wrapped, eps=0.01)\n",
    "adv_trainer = AdversarialTrainer(model_wrapped, attacks=fgm, ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_adv = load_model('cifar10_adv.h5')\n",
    "except:\n",
    "    history = adv_trainer.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        nb_epochs=10,\n",
    "        validation_data=(x_test, y_test),\n",
    "        batch_size=128,\n",
    "    )\n",
    "    model_adv.save('cifar10_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adversarially Trained Network')\n",
    "print(f'Label = {text_labels[label.argmax(1)[0]]}')\n",
    "plot_image_and_probs(perturbed_image_numpy, model_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. Is the trained model robust to any small perturbations? Play around with it. You will find that although more robust than the original model, it is still brittle.\n",
    "2. Combine adversarial training with the regularization techniques introduced earlier to build an accurate and robust model. You may need to do some parameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
