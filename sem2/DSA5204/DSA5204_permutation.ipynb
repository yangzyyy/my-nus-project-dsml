{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we investigate some issues with FCNN that is a little peculiar, namely its behavior with respect to permutations on image pixels.\n",
    "\n",
    "In passing, we will also introduce some useful aspects of `keras`, namely\n",
    "  * `Lambda` and `Flatten` layers as simple examples of preprocessing\n",
    "  * the `evaluate` method to evaluate model performance\n",
    "  * `get_weight` and `set_weight` methods to interact with variables in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sns.set(font_scale=1.5)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Simple Shallow NN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a simple one-hidden layer fully connected NN (FCNN) on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we processed the input data in two ways\n",
    "1. Normalize\n",
    "```python\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "```\n",
    "2. Reshape into vector\n",
    "```python\n",
    "    x_train = x_train.reshape(-1, 784)\n",
    "    x_test = x_test.reshape(-1, 784)\n",
    "```\n",
    "\n",
    "Here, we show how these processes can be directly incorporated into `keras` layers. This is an alternative way to do things, with many advantages, e.g. if your preprocessing step is compute intensive, then doing this can greatly improve performance, as computations can be performed in parallel to training, and/or on the GPU. \n",
    "\n",
    "We will only perform the basic scaling and reshaping using ready-made `keras` layers. For more advanced usage, be sure to check the corresponding pre-processing modules available in keras\n",
    "  * https://keras.io/preprocessing/image/\n",
    "  * https://keras.io/preprocessing/sequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Lambda, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add first a normalization layer by dividing all pixel values by 255. This can be done using the `Lambda` layer, which is a flexible way to build custom layers.\n",
    "\n",
    "**Remark** For backprop to work, it is *very* important that the function defining the Lambda layer be written in tensorflow to facilitate automatic differentiation. In other words, all math operations should either be performed using `tf.<some_op>` or those can be overloaded with tensorflow ops. In the example here, divide is overloaded, so that when you call `x/255` on a tensorflow tensor `x`, it is equivalent to calling `tf.math.divide(x, 255)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Lambda(lambda x: x / 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform the reshape operation to convert the input tensors from [:, 28, 28] to [:, 784]. This can be performed in three ways\n",
    "  * `Reshape` layer, which requires us to specific the new shape\n",
    "  * `Flatten` layer, which converts any tensor [:, a_1, a_2, ..., a_n] into [:, a_1*...*a_n]\n",
    "  * `Lambda` layer, which you define what to do\n",
    "\n",
    "We will use the `Flatten` since it is the simplest option here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us build the rest of the network as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce clutter, we will use a progress bar callback. This is provided by `tqdm.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    verbose=0,\n",
    "    callbacks=[TqdmCallback(verbose=1)]\n",
    ")\n",
    "results = pd.DataFrame(history.history)\n",
    "results['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(x='epoch', y=['accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write a handy function to evaluate performance on training and test sets, based on the `evaluate` method of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, test_data):\n",
    "    eval_train = model.evaluate(*train_data, batch_size=512, verbose=0)\n",
    "    eval_test = model.evaluate(*test_data, batch_size=512, verbose=0)\n",
    "    print(f'Train - loss = {eval_train[0]:.3f}, acc = {eval_train[1]:.3f} ')\n",
    "    print(f'Test - loss = {eval_test[0]:.3f}, acc = {eval_test[1]:.3f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, train_data=(x_train, y_train), test_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us investigate what happens when we permute the pixels of these images. We first plot two images in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.heatmap(x_train[0], ax=ax1, xticklabels=[], yticklabels=[])\n",
    "sns.heatmap(x_train[1], ax=ax2, xticklabels=[], yticklabels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the Pixels Randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write some functions for generating common permutations of images. Of course, there are much more efficient implementations of permutations in numpy. However, we are going to use pair-wise swaps to generate permutations.\n",
    "\n",
    "**Remark** Recall that any permutation of $\\{1,2,...,n\\}$ can be decomposed into the composition of pair-wise swaps, so the latter indeed can generate any permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle_indices(n):\n",
    "    \"\"\"\n",
    "    Return permutation index formed by\n",
    "    n pairwise swaps\n",
    "    \"\"\"\n",
    "    shuf_idx = np.arange(784)\n",
    "    for _ in range(n):\n",
    "        i, j = np.random.choice(784, size=(2, ), replace=False)\n",
    "        shuf_idx[i], shuf_idx[j] = shuf_idx[j], shuf_idx[i]\n",
    "    return shuf_idx\n",
    "\n",
    "def shuffle_image(image, shuf_idx):\n",
    "    \"\"\"\n",
    "    Shuffle one or more images according\n",
    "    to shuffle index shuf_idx\n",
    "    \"\"\"\n",
    "    if image.ndim == 2:\n",
    "        image = image[None, :, :]\n",
    "    image = image.reshape(image.shape[0], -1)\n",
    "    image = image[:, shuf_idx]\n",
    "    return image.reshape(-1, 28, 28).squeeze()\n",
    "\n",
    "def shuffle_and_eval(n_swap):\n",
    "    # Shuffle by swapping\n",
    "    print(f'Shuffle images by {n_swap} swaps')\n",
    "    shuf_idx = get_shuffle_indices(n_swap)\n",
    "    x_train_shuf = shuffle_image(x_train, shuf_idx)\n",
    "    x_test_shuf = shuffle_image(x_test, shuf_idx)\n",
    "    \n",
    "    # Plot shuffled images\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.heatmap(x_train_shuf[0],\n",
    "                ax=ax1,\n",
    "                xticklabels=[],\n",
    "                yticklabels=[])\n",
    "    sns.heatmap(x_train_shuf[1],\n",
    "                ax=ax2,\n",
    "                xticklabels=[],\n",
    "                yticklabels=[])\n",
    "\n",
    "    evaluate(model, (x_train_shuf, y_train), (x_test_shuf, y_test))\n",
    "    \n",
    "    return shuf_idx, x_train_shuf, x_test_shuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us look at the effect of permutation on the images and on model performance. The latter can be obtained by calling the `evaluate` method on models. It returns a list of values, starting with the loss and followed by the list of metrics provided in the `compile` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_idx, x_train_shuf, x_test_shuf = shuffle_and_eval(n_swap=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, once n_swaps is around 1000, to the human eye it is impossible to distinguish these images. As one may expect, the trained model also cannot distinguish the images, and gives an accuracy of about 10%, which is what one will get by randomly guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we really not handle permutations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the above result mean that FCNN cannot deal with permuted images? The answer is no. It turns out that we don't even have to retrain the FCNN model to handle these with ease. \n",
    "\n",
    "We will do something with the `magic` function below to the trained model. Take a look at the function to understand what is going on. Also, note how to interact with the model weights by `get_weights` and `set_weights` methods.\n",
    "\n",
    "**Note:** You can also achieve the same by using methods available from tensorflow 2.0 onwards, i.e.\n",
    "```python\n",
    "W, b, w, c = [w.numpy() for w in model.weights]  # same as model.get_weights()\n",
    "```\n",
    "and you can use the `assign` method available to tensors in model.weights to set weights individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def magic(model):\n",
    "    \"\"\"\n",
    "    Shuffles the first kernel (W)\n",
    "    by shuf_idx\n",
    "    \"\"\"\n",
    "    W, b, w, c = model.get_weights()\n",
    "    W_shuf = W[shuf_idx, :]\n",
    "    model.set_weights([W_shuf, b, w, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, (x_train_shuf, y_train), (x_test_shuf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Train a fresh FCNN model, but on randomly permuted images. Can they still be learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation and Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now train a convolutional neural network for this model. We will use 3 convolution-maxpool blocks followed by a 2-hidden-layer FCNN as our network. This is a fairly simple network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate a Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Normalize and Reshape into [samples, height, width, channels]\n",
    "model.add(Lambda(lambda x: x / 255))\n",
    "model.add(Reshape((28, 28, 1)))\n",
    "\n",
    "# Conv - Maxpool x 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Flatten - FC (2 hidden layers)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "model.add(Dense(units=84, activation='relu'))\n",
    "model.add(Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check if a saved file containing trained weights exist. If not, train a new one and if so, load the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('cnn_mnist_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_path.exists():\n",
    "    _ = model.predict(x_test, batch_size=512, verbose=0)  # call model once to make weights\n",
    "    model.load_weights(filepath=str(save_path))\n",
    "else:\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "        verbose=0,\n",
    "        callbacks=[TqdmCallback(verbose=1)]\n",
    "    )\n",
    "    results = pd.DataFrame(history.history)\n",
    "    results['epoch'] = history.epoch\n",
    "    results.plot(x='epoch', y=['accuracy', 'val_accuracy'])\n",
    "    model.save_weights(str(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, (x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Train the above CNN on the permuted images. Do we still expect to get back the same accuracy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
